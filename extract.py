import os
import re
from pathlib import Path


# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install pdfplumber python-docx

def extract_text_from_file(file_path):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ PDF, DOCX, DOC –∏ TXT

    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

    Returns:
        –¢–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    try:
        file_extension = Path(file_path).suffix.lower()

        if file_extension == '.pdf':
            return extract_text_from_pdf(file_path)
        elif file_extension == '.docx':
            return extract_text_from_docx(file_path)
        elif file_extension == '.doc':
            return extract_text_from_doc(file_path)
        elif file_extension == '.txt':
            return extract_text_from_txt(file_path)
        else:
            print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_extension}")
            return None

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return None


# ============= PDF =============

import pdfplumber


def extract_text_from_pdf(pdf_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
    print(f"üìÑ –ß–∏—Ç–∞—é PDF: {pdf_path}")

    try:
        text_parts = []

        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages, 1):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                page_text = page.extract_text()
                if page_text:
                    text_parts.append(page_text)
                else:
                    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–µ–º OCR –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏–º
                    print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")

        full_text = '\n\n'.join(text_parts)
        print(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(pdf.pages)} —Å—Ç—Ä–∞–Ω–∏—Ü, {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return full_text

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF: {e}")
        return None


# ============= DOCX =============

from docx import Document


def extract_text_from_docx(docx_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOCX —Ñ–∞–π–ª–∞"""
    print(f"üìÑ –ß–∏—Ç–∞—é DOCX: {docx_path}")

    try:
        doc = Document(docx_path)
        text_parts = []

        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text_parts.append(paragraph.text)

        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∞–±–ª–∏—Ü—ã
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text.strip():
                        text_parts.append(cell.text)

        full_text = '\n\n'.join(text_parts)
        print(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return full_text

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ DOCX: {e}")
        return None


# ============= DOC (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç) =============

def extract_text_from_doc(doc_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOC —Ñ–∞–π–ª–∞ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)"""
    print(f"üìÑ –ß–∏—Ç–∞—é DOC: {doc_path}")

    try:
        # –î–ª—è DOC —Ñ–∞–π–ª–æ–≤ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
        # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –∞–Ω—Ç–∏–≤–∞—Ç–Ω—ã–π textract –∏–ª–∏ python-doc
        import subprocess
        import tempfile

        # –°–ø–æ—Å–æ–± 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º antiword (–Ω—É–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å)
        try:
            result = subprocess.run(['antiword', doc_path],
                                    capture_output=True, text=True, encoding='utf-8')
            if result.returncode == 0:
                text = result.stdout
                print(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ (—á–µ—Ä–µ–∑ antiword)")
                return text
        except FileNotFoundError:
            print("‚ö†Ô∏è  antiword –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–±—É—é –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã...")

        # –°–ø–æ—Å–æ–± 2: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ txt —á–µ—Ä–µ–∑ LibreOffice
        try:
            with tempfile.NamedTemporaryFile(suffix='.txt', delete=False) as tmp:
                tmp_path = tmp.name

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ LibreOffice
            subprocess.run(['libreoffice', '--headless', '--convert-to', 'txt',
                            doc_path, '--outdir', os.path.dirname(tmp_path)],
                           capture_output=True)

            txt_file = doc_path.replace('.doc', '.txt')
            if os.path.exists(txt_file):
                with open(txt_file, 'r', encoding='utf-8', errors='ignore') as f:
                    text = f.read()
                os.remove(txt_file)  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                print(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ (—á–µ—Ä–µ–∑ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é)")
                return text
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")

        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å DOC —Ñ–∞–π–ª. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ antiword –∏–ª–∏ LibreOffice")
        return None

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ DOC: {e}")
        return None


# ============= TXT =============

def extract_text_from_txt(txt_path):
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ TXT —Ñ–∞–π–ª–∞"""
    print(f"üìÑ –ß–∏—Ç–∞—é TXT: {txt_path}")

    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        encodings = ['utf-8', 'cp1251', 'koi8-r', 'iso-8859-1']

        for encoding in encodings:
            try:
                with open(txt_path, 'r', encoding=encoding) as f:
                    text = f.read()
                print(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ (–∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding})")
                return text
            except UnicodeDecodeError:
                continue

        # –ï—Å–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, —á–∏—Ç–∞–µ–º —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫
        with open(txt_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        print(f"‚ö†Ô∏è  –ü—Ä–æ—á–∏—Ç–∞–Ω–æ —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return text

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ TXT: {e}")
        return None


# ============= –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° –í–ê–®–ò–ú –ö–û–î–û–ú =============

from transformers import T5ForConditionalGeneration, T5Tokenizer
import torch


def generate_title_from_file(file_path):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: —Ñ–∞–π–ª ‚Üí —Ç–µ–∫—Å—Ç ‚Üí –Ω–∞–∑–≤–∞–Ω–∏–µ
    """
    # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
    text = extract_text_from_file(file_path)

    if not text:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞")
        return None

    # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –≤–∞—à–µ–π —Ñ—É–Ω–∫—Ü–∏–µ–π
    model_path = "./models/rut5_base_sum_gazeta"

    try:
        tokenizer = T5Tokenizer.from_pretrained(model_path, local_files_only=True)
        model = T5ForConditionalGeneration.from_pretrained(model_path, local_files_only=True)
        model.to('cpu')

        # –ë–µ—Ä–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = text[:600]

        # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        prompt = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {context}"

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=400)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=50,
                min_length=15,
                num_beams=3,
                early_stopping=True,
                repetition_penalty=1.3,
                length_penalty=1.0,
                no_repeat_ngram_size=2
            )

        title = tokenizer.decode(outputs[0], skip_special_tokens=True)
        title = title.replace("–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞:", "").replace("–ó–∞–≥–æ–ª–æ–≤–æ–∫:", "").strip()

        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        if '.' in title:
            title = title.split('.')[0].strip()

        # –î–æ 25 —Å–ª–æ–≤ –º–∞–∫—Å–∏–º—É–º
        words = title.split()
        if len(words) > 25:
            title = " ".join(words[:25])

        return title.strip()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è: {e}")
        return None


# ============= –ü–ê–ö–ï–¢–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê =============

def process_folder(folder_path, output_file=None):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
    """
    import json
    from datetime import datetime

    print(f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø–∞–ø–∫—É: {folder_path}")

    results = []
    supported_extensions = ['.pdf', '.docx', '.doc', '.txt']

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    all_files = []
    for ext in supported_extensions:
        all_files.extend(Path(folder_path).glob(f"*{ext}"))
        all_files.extend(Path(folder_path).glob(f"*{ext.upper()}"))

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")

    for file_path in all_files:
        print(f"\n{'=' * 60}")
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {file_path.name}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
        title = generate_title_from_file(str(file_path))

        if title:
            result = {
                'filename': file_path.name,
                'title': title,
                'path': str(file_path),
                'processed_at': datetime.now().isoformat(),
                'word_count': len(title.split())
            }
            results.append(result)

            print(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ: {title}")
            print(f"üìè –°–ª–æ–≤: {len(title.split())}")
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if output_file and results:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

    return results


# ============= –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø =============

if __name__ == "__main__":
    import sys

    print("üéØ –°–ò–°–¢–ï–ú–ê –û–ë–†–ê–ë–û–¢–ö–ò –î–û–ö–õ–ê–î–û–í")
    print("=" * 60)

    if len(sys.argv) > 1:
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ –ø–∞–ø–∫–µ
        input_path = sys.argv[1]

        if os.path.isfile(input_path):
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            title = generate_title_from_file(input_path)
            if title:
                print(f"\nüè∑Ô∏è  –ù–∞–∑–≤–∞–Ω–∏–µ: {title}")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª")

        elif os.path.isdir(input_path):
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏
            output_file = "results.json"
            if len(sys.argv) > 2:
                output_file = sys.argv[2]

            process_folder(input_path, output_file)
        else:
            print(f"‚ùå –ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
    else:
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:")
        print("1. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª")
        print("2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–∞–ø–∫—É —Å —Ñ–∞–π–ª–∞–º–∏")
        print("3. –í—ã—Ö–æ–¥")

        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-3): ").strip()

        if choice == "1":
            file_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É: ").strip()
            if os.path.exists(file_path):
                title = generate_title_from_file(file_path)
                if title:
                    print(f"\nüè∑Ô∏è  –ù–∞–∑–≤–∞–Ω–∏–µ: {title}")
                else:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª")
            else:
                print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

        elif choice == "2":
            folder_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ: ").strip()
            if os.path.isdir(folder_path):
                output_file = input("–ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é results.json): ").strip()
                if not output_file:
                    output_file = "results.json"
                process_folder(folder_path, output_file)
            else:
                print("‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
import os
from pathlib import Path
from transformers import T5ForConditionalGeneration, T5Tokenizer
import torch

# ============= –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –¢–ï–ö–°–¢–ê –ò–ó –§–ê–ô–õ–û–í =============

try:
    import pdfplumber

    PDF_SUPPORT = True
except ImportError:
    print("‚ö†Ô∏è  pdfplumber –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è —Ä–∞–±–æ—Ç—ã —Å PDF —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pdfplumber")
    PDF_SUPPORT = False

try:
    from docx import Document

    DOCX_SUPPORT = True
except ImportError:
    print("‚ö†Ô∏è  python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è —Ä–∞–±–æ—Ç—ã —Å DOCX —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")
    DOCX_SUPPORT = False


def extract_text_from_file(file_path):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ PDF, DOCX, DOC, TXT

    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

    Returns:
        –¢–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    try:
        file_extension = Path(file_path).suffix.lower()

        if file_extension == '.pdf' and PDF_SUPPORT:
            return extract_text_from_pdf(file_path)
        elif file_extension == '.docx' and DOCX_SUPPORT:
            return extract_text_from_docx(file_path)
        elif file_extension == '.txt':
            return extract_text_from_txt(file_path)
        else:
            print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞: {file_extension}")
            return None

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {str(e)[:100]}")
        return None


def extract_text_from_pdf(pdf_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
    try:
        text_parts = []

        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages, 1):
                page_text = page.extract_text()
                if page_text:
                    text_parts.append(page_text)

        full_text = '\n\n'.join(text_parts)
        if full_text:
            print(f"üìÑ PDF: –ø—Ä–æ—á–∏—Ç–∞–Ω–æ {len(pdf.pages)} —Å—Ç—Ä–∞–Ω–∏—Ü, {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        else:
            print(f"‚ö†Ô∏è  PDF: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç (–≤–æ–∑–º–æ–∂–Ω–æ, —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç)")
        return full_text

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF: {str(e)[:100]}")
        return None


def extract_text_from_docx(docx_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOCX —Ñ–∞–π–ª–∞"""
    try:
        doc = Document(docx_path)
        text_parts = []

        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text_parts.append(paragraph.text)

        full_text = '\n\n'.join(text_parts)
        print(f"üìÑ DOCX: –ø—Ä–æ—á–∏—Ç–∞–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return full_text

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ DOCX: {str(e)[:100]}")
        return None


def extract_text_from_txt(txt_path):
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ TXT —Ñ–∞–π–ª–∞"""
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        encodings = ['utf-8', 'cp1251', 'koi8-r']

        for encoding in encodings:
            try:
                with open(txt_path, 'r', encoding=encoding) as f:
                    text = f.read()
                print(f"üìÑ TXT: –ø—Ä–æ—á–∏—Ç–∞–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ (–∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding})")
                return text
            except UnicodeDecodeError:
                continue

        # –ï—Å–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, —á–∏—Ç–∞–µ–º —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫
        with open(txt_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        print(f"üìÑ TXT: –ø—Ä–æ—á–∏—Ç–∞–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ (—Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫)")
        return text

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ TXT: {str(e)[:100]}")
        return None


# ============= –ì–ï–ù–ï–†–ê–¶–ò–Ø –ê–ù–ù–û–¢–ê–¶–ò–ò –î–û 35 –°–õ–û–í =============

def generate_annotation(text, max_words=35, model_path="./models/rut5_base_sum_gazeta"):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é (–Ω–∞–∑–≤–∞–Ω–∏–µ) –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤

    Args:
        text: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
        max_words: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 35)
        model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏

    Returns:
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è
    """
    if not text or len(text.strip()) == 0:
        return "–¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        tokenizer = T5Tokenizer.from_pretrained(model_path, local_files_only=True)
        model = T5ForConditionalGeneration.from_pretrained(model_path, local_files_only=True)
        model.to('cpu')

        # –ê–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç max_words
        if max_words <= 15:
            max_length = 40
            length_penalty = 1.2
        elif max_words <= 25:
            max_length = 55
            length_penalty = 1.0
        elif max_words <= 35:
            max_length = 70
            length_penalty = 0.9
        else:  # >35
            max_length = 85
            length_penalty = 0.8

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_length = min(500 + (max_words * 10), 1000)
        context = text[:context_length]

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {context}"
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=max_length,
                min_length=max(15, int(max_words * 0.3)),  # –ú–∏–Ω–∏–º—É–º 30% –æ—Ç max_words
                num_beams=3,
                early_stopping=True,
                repetition_penalty=1.2,
                length_penalty=length_penalty,
                no_repeat_ngram_size=2
            )

        # –ü–æ–ª—É—á–∞–µ–º –∏ –æ—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        title = tokenizer.decode(outputs[0], skip_special_tokens=True)
        title = title.replace("–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞:", "").replace("–ó–∞–≥–æ–ª–æ–≤–æ–∫:", "").strip()

        # –ë–µ—Ä–µ–º –¥–æ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ
        sentences = title.split('.')
        if len(sentences) > 1:
            first = sentences[0].strip()
            if len(first.split()) >= 5:
                title = first
            elif len('. '.join(sentences[:2]).strip().split()) <= max_words:
                title = '. '.join(sentences[:2]).strip()

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Ç–æ—á–∫–∏
        title = title.rstrip('. ')

        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ max_words
        words = title.split()
        if len(words) > max_words:
            title = " ".join(words[:max_words])

        return title.strip()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {str(e)[:100]}")
        return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"


# ============= –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –†–ê–ë–û–¢–´ –° –§–ê–ô–õ–ê–ú–ò =============

def generate_annotation_from_file(file_path, max_words=35):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: —Ñ–∞–π–ª ‚Üí —Ç–µ–∫—Å—Ç ‚Üí –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è

    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (PDF, DOCX, TXT)
        max_words: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏

    Returns:
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    """
    print(f"\n{'=' * 60}")
    print(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {Path(file_path).name}")
    print(f"{'=' * 60}")

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not os.path.exists(file_path):
        return f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}"

    # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
    text = extract_text_from_file(file_path)
    if not text:
        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞"

    # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
    print("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é...")
    annotation = generate_annotation(text, max_words=max_words)

    return annotation


# ============= –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø =============

if __name__ == "__main__":
    import sys

    print("üéØ –°–ò–°–¢–ï–ú–ê –ì–ï–ù–ï–†–ê–¶–ò–ò –ê–ù–ù–û–¢–ê–¶–ò–ô –î–õ–Ø –î–û–ö–£–ú–ï–ù–¢–û–í")
    print("=" * 60)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    if not PDF_SUPPORT:
        print("–î–ª—è —Ä–∞–±–æ—Ç—ã —Å PDF —Ñ–∞–π–ª–∞–º–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pdfplumber")
    if not DOCX_SUPPORT:
        print("–î–ª—è —Ä–∞–±–æ—Ç—ã —Å DOCX —Ñ–∞–π–ª–∞–º–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        # –†–µ–∂–∏–º –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏: python script.py –ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É [–º–∞–∫—Å_—Å–ª–æ–≤]
        file_path = sys.argv[1]
        max_words = 35
        if len(sys.argv) > 2:
            try:
                max_words = int(sys.argv[2])
            except ValueError:
                print(f"‚ö†Ô∏è  –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ —Å–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é {max_words}")

        result = generate_annotation_from_file(file_path, max_words)
        print(f"\nüè∑Ô∏è  –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è ({len(result.split())} —Å–ª–æ–≤):")
        print(f"   {result}")

    else:
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:")
        print("1. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª")
        print("2. –í—ã—Ö–æ–¥")

        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-2): ").strip()

        if choice == "1":
            file_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (PDF, DOCX, TXT): ").strip()

            if not os.path.exists(file_path):
                print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            else:
                # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
                max_words_input = input("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ [35]: ").strip()
                max_words = 35
                if max_words_input:
                    try:
                        max_words = int(max_words_input)
                        if max_words < 5:
                            print("‚ö†Ô∏è  –ú–∏–Ω–∏–º—É–º 5 —Å–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é 5")
                            max_words = 5
                        elif max_words > 50:
                            print("‚ö†Ô∏è  –ú–∞–∫—Å–∏–º—É–º 50 —Å–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é 50")
                            max_words = 50
                    except ValueError:
                        print(f"‚ö†Ô∏è  –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ, –∏—Å–ø–æ–ª—å–∑—É—é {max_words}")

                result = generate_annotation_from_file(file_path, max_words)
                print(f"\nüè∑Ô∏è  –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è ({len(result.split())} —Å–ª–æ–≤):")
                print(f"   {result}")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª
                save_option = input("\n–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª? (y/n): ").strip().lower()
                if save_option == 'y':
                    output_file = f"{Path(file_path).stem}_–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è.txt"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(f"–§–∞–π–ª: {Path(file_path).name}\n")
                        f.write(f"–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è ({len(result.split())} —Å–ª–æ–≤):\n")
                        f.write("=" * 50 + "\n")
                        f.write(result + "\n")
                    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_file}")
        else:
            print("–í—ã—Ö–æ–¥")